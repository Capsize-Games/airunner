"""Lightweight TrainingMixin: manual deterministic training loop for adapters.

This file provides a single minimal implementation intended to replace the
previous corrupted/duplicated content. It focuses on clarity and robustness
for small adapter-style fine-tuning runs.
"""

from __future__ import annotations

import json
import os
from typing import List, Tuple
import torch
from datasets import Dataset
from peft import AutoPeftModel
from peft import (
    get_peft_model,
    LoraConfig,
    TaskType,
)
from peft import prepare_model_for_kbit_training
from transformers import PreTrainedModel
from torch.utils.data import DataLoader
from transformers import default_data_collator
from transformers import Trainer  # type: ignore
import bitsandbytes as bnb
import gc


class TrainingMixin:
    def __init__(self) -> None:
        self._model = None

    @property
    def adapter_path(self) -> str:
        base = self.path_settings.base_path
        return os.path.expanduser(
            os.path.join(
                base, "text", "models", "llm", "adapters", self.model_version
            )
        )

    def prepare_tokenizer(self):
        if self.tokenizer is None:
            raise RuntimeError("Tokenizer not available for training")

        # Ensure the tokenizer has a pad token to avoid padding errors
        try:
            if getattr(self.tokenizer, "pad_token", None) is None:
                # prefer eos_token, otherwise add a new pad token
                if getattr(self.tokenizer, "eos_token", None) is not None:
                    self.tokenizer.pad_token = self.tokenizer.eos_token
                else:
                    try:
                        self.tokenizer.add_special_tokens(
                            {"pad_token": "[PAD]"}
                        )
                    except Exception:
                        # last resort: set pad_token to unknown token
                        self.tokenizer.pad_token = getattr(
                            self.tokenizer, "unk_token", "[PAD]"
                        )
        except Exception:
            pass

    def prepare_data(self, training_data: List[Tuple[str, str]]):
        def fmt(q: str, a: str) -> str:
            return f"<s>[INST] {q} [/INST]{a}</s>"
        
        texts = [fmt(q[0], q[1]) for q in training_data]

        # Tokenize directly (avoids non-picklable local functions in Dataset.map)
        # Some test fakes or tokenizers may not accept `return_tensors` kwarg,
        # so call with a minimal set and handle the returned mapping.
        tokenized = self.tokenizer(
            texts, truncation=True, padding="max_length", max_length=128
        )
        # ensure labels are present
        try:
            tokenized["labels"] = [
                list(ids) for ids in tokenized.get("input_ids", [])
            ]
        except Exception:
            tokenized["labels"] = tokenized.get("input_ids", [])

        # Build a Dataset from the tokenized mapping
        try:
            dataset = Dataset.from_dict(tokenized)
            tokenized = dataset
        except Exception:
            # fallback: keep tokenized as a list-of-dicts and let DataLoader handle later
            # convert to list of dicts if necessary
            if isinstance(tokenized.get("input_ids"), list):
                tokenized = [
                    {k: v[i] for k, v in tokenized.items()}
                    for i in range(len(tokenized["input_ids"]))
                ]
        return tokenized

    def _load_peft_model(self):
        return self.model

    @property
    def is_transformers_model(self) -> bool:
        # If no adapter was applied, try to create a LoRA adapter (PEFT) so
        # we fine-tune only the adapter parameters instead of the full model.
        model_looks_transformers = False
        try:
            if PreTrainedModel is not None and isinstance(
                self._model, PreTrainedModel
            ):
                model_looks_transformers = True
            else:
                # heuristic fallback: check for common HF attributes
                if hasattr(self._model, "state_dict") or hasattr(
                    self._model, "config"
                ):
                    model_looks_transformers = True
        except Exception:
            model_looks_transformers = False
        return model_looks_transformers

    def train(
        self,
        training_data: List[Tuple[str, str]],
        training_steps: int = 10,
        username: str | None = None,
        botname: str | None = None,
        progress_callback=None,
        **kwargs,
    ) -> None:
        """Minimal manual training loop for adapter fine-tuning.

        Expects: self.tokenizer and self._model to be set by the caller.
        """
        self.prepare_tokenizer()
        train_dataset = self.prepare_data(training_data)
        self.model = self._load_peft_model()

        # If model is not already PEFT-wrapped and looks like a transformers
        # model, attempt to create a new LoRA adapter in-memory (requires `peft`).
        # Do this even if an adapter directory exists but loading failed; we
        # should not fall back to full-model training inadvertently.
        if self.model_looks_transformers:

            # LoRA defaults; allow overrides via kwargs
            lora_r = int(kwargs.get("lora_r", 8))
            lora_alpha = int(kwargs.get("lora_alpha", 32))
            lora_dropout = float(kwargs.get("lora_dropout", 0.05))
            target_modules = kwargs.get(
                "lora_target_modules",
                ["q_proj", "v_proj", "k_proj", "o_proj"],
            )

            try:
                lora_config = LoraConfig(
                    r=lora_r,
                    lora_alpha=lora_alpha,
                    target_modules=target_modules,
                    lora_dropout=lora_dropout,
                    bias="none",
                    task_type=TaskType.CAUSAL_LM,
                )

                # If available, prepare model for k-bit training (no-op otherwise)
                try:
                    self._model = prepare_model_for_kbit_training(self._model)
                except Exception:
                    # prepare_model_for_kbit_training may not exist; ignore
                    pass

                self._model = get_peft_model(self._model, lora_config)
                self.logger.info(
                    "Applied in-memory LoRA adapter; training adapter params only."
                )
                # Ensure only adapter params are trainable: freeze base model
                try:
                    for n, p in list(self._model.named_parameters()):
                        # default to frozen
                        p.requires_grad = False

                    # enable training for adapter parameters heuristically
                    adapter_keywords = [
                        "lora",
                        "adapter",
                        "alpha",
                        "up",
                        "down",
                    ]
                    enabled = 0
                    for n, p in list(self._model.named_parameters()):
                        lower = n.lower()
                        if any(k in lower for k in adapter_keywords):
                            p.requires_grad = True
                            enabled += 1

                    self.logger.info(
                        f"Adapter parameters enabled for training: {enabled}"
                    )

                    # If model supports gradient checkpointing, enable it to reduce memory
                    try:
                        if hasattr(
                            self._model, "gradient_checkpointing_enable"
                        ):
                            self._model.gradient_checkpointing_enable()
                    except Exception:
                        pass
                except Exception:
                    # If anything goes wrong, continue; training will validate trainable params later
                    pass
            except Exception as e:
                self.logger.error(f"Failed to create/apply LoRA adapter: {e}")
                raise RuntimeError(f"Failed to create LoRA adapter: {e}")

        # If the model isn't a torch-like model with parameters (tests may set a
        # dummy object), fall back to a Trainer-based or no-op path to allow
        # unit tests to run without requiring real model objects.
        if not hasattr(self._model, "parameters"):
            try:
                if Trainer is not None:
                    # Use the (possibly monkeypatched) Trainer to run a no-op
                    # training invocation with the tokenized dataset.
                    trainer = Trainer(
                        model=self._model,
                        args=None,
                        train_dataset=train_dataset,
                    )
                    trainer.train()
                    return
            except Exception:
                # swallow and continue to safe no-op
                return

        # Safety: avoid accidentally fine-tuning the full base model (which
        # can easily exhaust GPU memory for multi-billion-parameter models).
        # Prefer adapter/PEFT workflows. Require explicit confirmation to
        # perform full-model training via force_full_finetune=True.
        force_full = bool(kwargs.get("force_full_finetune", False))

        # If no adapter is present and model is not a AutoPeftModel, refuse by default
        if os.path.exists(self.adapter_path):
            # compute simple parameter counts for diagnostics
            try:
                total_params = 0
                trainable_params = 0
                for p in getattr(self._model, "parameters", lambda: [])():
                    total_params += int(getattr(p, "numel", lambda: 0)())
                    if getattr(p, "requires_grad", False):
                        trainable_params += int(
                            getattr(p, "numel", lambda: 0)()
                        )
            except Exception:
                total_params = None
                trainable_params = None

            if not force_full:
                msg = (
                    "Training would run on the full base model (no adapter found). "
                    "This typically requires large amounts of GPU memory for multi-"
                    "billion-parameter models and will likely OOM."
                )
                if total_params is not None:
                    msg += f" Model params={total_params:,}, trainable={trainable_params:,}."
                msg += " Create/apply a PEFT adapter (LoRA) or re-run with force_full_finetune=True if you really intend a full fine-tune."
                raise RuntimeError(msg)

        # If the model isn't a torch-like model with parameters (tests may set a
        # dummy object), fall back to a Trainer-based or no-op path to allow
        # unit tests to run without requiring real model objects.
        if not hasattr(self._model, "parameters"):
            try:
                if Trainer is not None:
                    # Use the (possibly monkeypatched) Trainer to run a no-op
                    # training invocation with the tokenized dataset.
                    trainer = Trainer(
                        model=self._model, args=None, train_dataset=tokenized
                    )
                    trainer.train()
                    return
            except Exception:
                # swallow and continue to safe no-op
                return

        try:
            collate = default_data_collator
            dl = DataLoader(tokenized, batch_size=1, collate_fn=collate)

            try:
                device = next(self._model.parameters()).device
            except Exception:
                device = torch.device("cpu")

            trainable = [
                p for p in self._model.parameters() if p.requires_grad
            ]
            if not trainable:
                raise RuntimeError(
                    "No trainable parameters found for fine-tuning"
                )

            # Prefer bitsandbytes 8-bit optimizer when available to reduce optimizer RAM
            optimizer = None
            try:
                try:
                    optimizer = bnb.optim.AdamW8bit(trainable, lr=2e-4)
                    self.logger.info(
                        "Using bitsandbytes AdamW8bit optimizer for training"
                    )
                except Exception:
                    optimizer = None
            except Exception:
                optimizer = None

            if optimizer is None:
                optimizer = torch.optim.AdamW(trainable, lr=2e-4)

            # Small memory hygiene before starting heavy compute
            try:
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
            except Exception:
                pass

            self._model.train()
            steps = 0
            total = max(1, int(training_steps))
            for batch in dl:
                for k, v in list(batch.items()):
                    try:
                        batch[k] = v.to(device)
                    except Exception:
                        pass

                out = None
                try:
                    out = self._model(**batch)
                except Exception:
                    try:
                        ii = batch.get("input_ids")
                        if ii is not None:
                            out = self._model(input_ids=ii)
                    except Exception:
                        out = None

                loss = None
                if out is not None:
                    loss = getattr(out, "loss", None)

                if loss is None:
                    raise RuntimeError(
                        "Could not obtain loss from model output"
                    )

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                steps += 1
                # emit progress if callback provided
                try:
                    if progress_callback is not None:
                        pct = int(100 * steps / total) if total > 0 else 100
                        progress_callback({"progress": pct, "step": steps})
                except Exception:
                    pass

                if steps >= training_steps:
                    break

            # Persist adapter: strict PEFT-first saving.
            try:
                os.makedirs(self.adapter_path, exist_ok=True)
            except Exception:
                pass

            try:
                if isinstance(self._model, AutoPeftModel):
                    # Use PEFT's documented save_pretrained for adapter artifacts
                    try:
                        self._model.save_pretrained(self.adapter_path)
                    except Exception as e:
                        # Log full traceback and attempt explicit state-dict fallback
                        self.logger.exception(
                            "AutoPeftModel.save_pretrained failed during training"
                        )
                        # Try PEFT getters for adapter-only state
                        peft_state = None
                        for getter in (
                            "get_peft_state_dict",
                            "get_adapter_state_dict",
                            "get_peft_model_state_dict",
                        ):
                            fn = getattr(self._model, getter, None)
                            if fn is None:
                                continue
                            try:
                                peft_state = fn()
                                if isinstance(peft_state, dict) and peft_state:
                                    break
                            except Exception:
                                self.logger.exception(
                                    f"PEFT getter {getter} failed"
                                )

                        if peft_state:
                            try:
                                out_path = os.path.join(
                                    self.adapter_path, "adapter_state_dict.pt"
                                )
                                torch.save(peft_state, out_path)
                                self.logger.warning(
                                    f"Wrote adapter_state_dict.pt fallback to {out_path}"
                                )
                            except Exception:
                                self.logger.exception(
                                    "Failed to write adapter_state_dict.pt fallback"
                                )
                        else:
                            raise RuntimeError(
                                "AutoPeftModel.save_pretrained failed and no PEFT getter returned a state dict"
                            )
                else:
                    # If we reach here, model is not a AutoPeftModel: refuse to
                    # write the full transformers model into an adapters folder.
                    msg = "Refusing to save full base model into adapter path because model is not a AutoPeftModel."
                    self.logger.error(msg)
                    raise RuntimeError(msg)
            except Exception:
                # Log the failure but do NOT re-raise here — allow the
                # subsequent `_save_finetuned_model` diagnostics/fallback to
                # attempt to extract and persist adapter parameters.
                self.logger.exception(
                    "AutoPeftModel adapter save failed during training; will attempt fallback diagnostics"
                )

            # Ensure adapter metadata is written so loaders can recognise the adapter
            try:
                self._save_finetuned_model()
            except Exception:
                pass

            # final progress callback
            try:
                if progress_callback is not None:
                    progress_callback({"progress": 100, "step": steps})
            except Exception:
                pass

        except Exception as err:
            # Log and re-raise so callers can handle the failure
            self.logger.error(f"Manual training failed: {err}")
            raise

    def _save_finetuned_model(self) -> None:
        try:
            os.makedirs(self.adapter_path, exist_ok=True)
        except Exception:
            pass

        # When persisting from this helper, use PEFT save_pretrained for
        # AutoPeftModel instances; otherwise refuse to write the full base model
        # into the adapter folder and attempt explicit PEFT getters as a
        # fallback.
        try:
            if isinstance(self._model, AutoPeftModel):
                try:
                    self._model.save_pretrained(self.adapter_path)
                except Exception:
                    self.logger.exception(
                        "AutoPeftModel.save_pretrained failed in _save_finetuned_model"
                    )
                    # fall through to PEFT getter fallback below
            else:
                # Model is not a AutoPeftModel — do not write full model into adapters
                msg = "_save_finetuned_model: model is not a AutoPeftModel; skipping full-model save into adapter path."
                self.logger.error(msg)
                raise RuntimeError(msg)
        except Exception:
            # Attempt fallback: try to obtain PEFT adapter state dict via getters
            try:
                peft_state = None
                for getter in (
                    "get_peft_state_dict",
                    "get_adapter_state_dict",
                    "get_peft_model_state_dict",
                ):
                    fn = getattr(self._model, getter, None)
                    if fn is None:
                        continue
                    try:
                        peft_state = fn()
                        if isinstance(peft_state, dict) and peft_state:
                            break
                    except Exception:
                        self.logger.exception(
                            f"PEFT getter {getter} failed in fallback"
                        )

                if peft_state:
                    try:
                        out_path = os.path.join(
                            self.adapter_path, "adapter_state_dict.pt"
                        )
                        torch.save(peft_state, out_path)
                        self.logger.warning(
                            f"Wrote adapter_state_dict.pt fallback to {out_path}"
                        )
                    except Exception:
                        self.logger.exception(
                            "Failed to write adapter_state_dict.pt in fallback"
                        )
                else:
                    # As a last resort, attempt to extract adapter-related
                    # tensors from the model's state_dict and write them.
                    try:
                        state = getattr(self._model, "state_dict", None)
                        if callable(state):
                            full = state()
                        else:
                            # Some model wrappers expose .state_dict as a mapping
                            full = state if state is not None else {}

                        adapter_keywords = (
                            "lora",
                            "adapter",
                            "alpha",
                            "up",
                            "down",
                        )
                        adapter_subset = {
                            k: v.cpu() if hasattr(v, "cpu") else v
                            for k, v in (full or {}).items()
                            if any(kw in k.lower() for kw in adapter_keywords)
                        }

                        if adapter_subset:
                            out_path = os.path.join(
                                self.adapter_path, "adapter_state_dict.pt"
                            )
                            try:
                                torch.save(adapter_subset, out_path)
                                self.logger.warning(
                                    f"Wrote adapter_state_dict.pt by filtering model.state_dict() to {out_path}"
                                )
                            except Exception:
                                self.logger.exception(
                                    "Failed to write adapter_state_dict.pt from state_dict fallback"
                                )
                        else:
                            self.logger.warning(
                                "State-dict fallback found no adapter-like keys to save."
                            )
                    except Exception:
                        self.logger.exception(
                            "State-dict fallback failed while attempting to persist adapter tensors"
                        )
            except Exception:
                self.logger.exception("Adapter fallback diagnostics failed")

        # If this is a PEFT model, attempt to persist adapter_config.json
        try:
            peft_cfg = None
            if isinstance(self._model, AutoPeftModel):
                peft_cfg = getattr(self._model, "peft_config", None)
            else:
                # If model is not wrapped (but an adapter was saved), try to
                # detect a nested attribute or saved config on the model object
                peft_cfg = getattr(self._model, "peft_config", None)

            if peft_cfg is not None:
                # Build a minimal dict containing common fields PEFT loader expects
                ac = {
                    "peft_type": getattr(peft_cfg, "peft_type", None),
                    "base_model_name_or_path": getattr(
                        peft_cfg, "base_model_name_or_path", None
                    ),
                    "task_type": getattr(peft_cfg, "task_type", None),
                    "inference_mode": getattr(
                        peft_cfg, "inference_mode", False
                    ),
                    "r": getattr(peft_cfg, "r", None),
                    "lora_alpha": getattr(peft_cfg, "lora_alpha", None),
                    "lora_dropout": getattr(peft_cfg, "lora_dropout", None),
                    "target_modules": getattr(
                        peft_cfg, "target_modules", None
                    ),
                }

                # Write adapter_config.json
                try:
                    with open(
                        os.path.join(self.adapter_path, "adapter_config.json"),
                        "w",
                        encoding="utf-8",
                    ) as f:
                        json.dump(ac, f, indent=2, default=str)
                except Exception:
                    # best-effort: do not fail if we can't write metadata
                    pass
        except Exception:
            pass

        try:
            with open(
                os.path.join(self.adapter_path, "tokenizer_config.json"),
                "w",
                encoding="utf-8",
            ) as f:
                json.dump(
                    {"name_or_path": getattr(self, "model_path", None)},
                    f,
                    indent=2,
                )
        except Exception:
            pass

        # Verify that some weight file was written. Common names/extensions
        # include: *.bin, *.pt, *.safetensors, adapter_model.bin, pytorch_model.bin
        try:
            files = []
            try:
                files = os.listdir(self.adapter_path)
            except Exception:
                files = []

            weight_files = [
                f
                for f in files
                if f.lower().endswith((".bin", ".pt", ".safetensors"))
                or "adapter" in f.lower()
                or "pytorch_model" in f.lower()
            ]

            if weight_files:
                self.logger.info(
                    f"Adapter saved to: {self.adapter_path} (files: {weight_files})"
                )
            else:
                # Best-effort fallback: attempt to extract adapter params and
                # save a small state dict so the adapter isn't completely lost.
                try:
                    adapter_state = {}
                    keywords = [
                        "lora",
                        "adapter",
                        "alpha",
                        "up",
                        "down",
                    ]
                    for n, p in getattr(
                        self._model, "named_parameters", lambda: []
                    )():
                        try:
                            lower = n.lower()
                        except Exception:
                            lower = ""
                        if any(k in lower for k in keywords):
                            try:
                                adapter_state[n] = p.detach().cpu()
                            except Exception:
                                # If tensor access fails, skip it
                                pass

                    if adapter_state:
                        out_path = os.path.join(
                            self.adapter_path, "adapter_state_dict.pt"
                        )
                        try:
                            torch.save(adapter_state, out_path)
                            self.logger.warning(
                                f"No standard adapter weight file found; wrote fallback adapter_state_dict at {out_path}"
                            )
                        except Exception as e:
                            self.logger.warning(
                                f"Failed to write fallback adapter_state_dict: {e}"
                            )
                    else:
                        # Provide more diagnostics: log peft_config if present,
                        # count parameters scanned and report if nothing matched.
                        try:
                            peft_cfg_debug = None
                            if isinstance(self._model, AutoPeftModel):
                                peft_cfg_debug = getattr(
                                    self._model, "peft_config", None
                                )
                            else:
                                peft_cfg_debug = getattr(
                                    self._model, "peft_config", None
                                )

                            # attempt to call common peft getters to recover adapter state
                            peft_state = None
                            for getter in (
                                "get_peft_state_dict",
                                "get_adapter_state_dict",
                                "get_peft_model_state_dict",
                                "get_peft_params",
                            ):
                                try:
                                    fn = getattr(self._model, getter, None)
                                    if fn is not None:
                                        peft_state = fn()
                                        if (
                                            isinstance(peft_state, dict)
                                            and peft_state
                                        ):
                                            break
                                except Exception:
                                    peft_state = None

                            # Log basic diagnostics
                            try:
                                total_params = 0
                                scanned = 0
                                for n, p in getattr(
                                    self._model, "named_parameters", lambda: []
                                )():
                                    total_params += 1
                                    try:
                                        ln = n.lower()
                                    except Exception:
                                        ln = ""
                                    if any(
                                        k in ln
                                        for k in (
                                            "lora",
                                            "adapter",
                                            "up",
                                            "down",
                                            "alpha",
                                        )
                                    ):
                                        scanned += 1
                            except Exception:
                                total_params = None
                                scanned = None

                            self.logger.warning(
                                "No adapter weight files detected and no adapter parameters found to save."
                            )
                            self.logger.debug(
                                f"PEFT config: {peft_cfg_debug}; total_named_params={total_params}; matched_adapter_params={scanned}"
                            )

                            # If a peft-specific getter returned a dict, try writing it
                            if isinstance(peft_state, dict) and peft_state:
                                try:
                                    out_path = os.path.join(
                                        self.adapter_path,
                                        "adapter_state_dict.pt",
                                    )
                                    torch.save(peft_state, out_path)
                                    self.logger.warning(
                                        f"Wrote adapter state via PEFT getter to {out_path}"
                                    )
                                except Exception as e:
                                    self.logger.warning(
                                        f"Failed to write peft_state fallback: {e}"
                                    )
                        except Exception as e:
                            # ensure we log at least something if diagnostics fail
                            self.logger.warning(
                                f"Adapter diagnostics failed: {e}"
                            )
                except Exception as e:
                    # If torch unavailable or other errors occur, log and continue
                    self.logger.warning(
                        f"Adapter save verification failed or torch not available: {e}"
                    )
        except Exception:
            # Do not propagate verification errors
            pass
