"""Bootstrap data for LLM models.

Format: {repo_id: {path_settings: str, context_length: int, capabilities: dict, files: {filename: expected_size_in_bytes}}}
File sizes are used to detect incomplete downloads and resume them.
This mirrors the SD_FILE_BOOTSTRAP_DATA format for consistency.

Capabilities:
- function_calling: Whether the model can call functions/tools reliably
- thinking_capable: Whether the model supports "thinking mode" with <think>...</think> reasoning blocks (Qwen3 only)
- rag_capable: Whether the model works well for RAG (retrieval augmented generation)
- vision_capable: Whether the model can process images
- code_capable: Whether the model is good at code generation
- is_embedding_model: Whether this is an embedding model (not a chat model)
"""

LLM_FILE_BOOTSTRAP_DATA = {
    "meta-llama/Llama-3.1-8B-Instruct": {
        "path_settings": "llm_causallm_model_path",
        "context_length": 131072,
        "capabilities": {
            "function_calling": True,
            "thinking_capable": False,
            "rag_capable": True,
            "vision_capable": False,
            "code_capable": True,
            "is_embedding_model": False,
        },
        "files": {
            "config.json": 855,
            "generation_config.json": 184,
            "model-00001-of-00004.safetensors": 4976698672,
            "model-00002-of-00004.safetensors": 4999802720,
            "model-00003-of-00004.safetensors": 4915916176,
            "model-00004-of-00004.safetensors": 1168138808,
            "model.safetensors.index.json": 23950,
            "special_tokens_map.json": 296,
            "tokenizer.json": 9085657,
            "tokenizer_config.json": 55351,
        },
    },
    "Qwen/Qwen3-8B-GGUF": {
        "path_settings": "llm_causallm_model_path",
        "context_length": 32768,
        "capabilities": {
            "function_calling": True,
            "thinking_capable": True,
            "rag_capable": True,
            "vision_capable": False,
            "code_capable": True,
            "is_embedding_model": False,
        },
        "files": {
            "Qwen3-8B-Q4_K_M.gguf": 5026889920,
        },
    },
    "CohereForAI/c4ai-command-r-08-2024": {
        "path_settings": "llm_causallm_model_path",
        "context_length": 131072,
        "capabilities": {
            "function_calling": True,
            "thinking_capable": False,
            "rag_capable": True,
            "vision_capable": False,
            "code_capable": True,
            "is_embedding_model": False,
        },
        "files": {
            "config.json": 639,
            "generation_config.json": 137,
            "model-00001-of-00014.safetensors": 4898947792,
            "model-00002-of-00014.safetensors": 4932553528,
            "model-00003-of-00014.safetensors": 4932570024,
            "model-00004-of-00014.safetensors": 4831890592,
            "model-00005-of-00014.safetensors": 4932553560,
            "model-00006-of-00014.safetensors": 4932553552,
            "model-00007-of-00014.safetensors": 4932570048,
            "model-00008-of-00014.safetensors": 4831890616,
            "model-00009-of-00014.safetensors": 4932553560,
            "model-00010-of-00014.safetensors": 4932553552,
            "model-00011-of-00014.safetensors": 4932570048,
            "model-00012-of-00014.safetensors": 4831890616,
            "model-00013-of-00014.safetensors": 4932553560,
            "model-00014-of-00014.safetensors": 805339584,
            "model.safetensors.index.json": 26206,
            "special_tokens_map.json": 439,
            "tokenizer.json": 12778456,
            "tokenizer_config.json": 21742,
        },
    },
    "mistralai/Ministral-8B-Instruct-2410": {
        "path_settings": "llm_causallm_model_path",
        "context_length": 131072,
        "capabilities": {
            "function_calling": True,
            "thinking_capable": False,
            "rag_capable": True,
            "vision_capable": False,
            "code_capable": True,
            "is_embedding_model": False,
        },
        "files": {
            "config.json": 1412,
            "generation_config.json": 116,
            "model-00001-of-00004.safetensors": 4983007904,
            "model-00002-of-00004.safetensors": 4999836776,
            "model-00003-of-00004.safetensors": 4983067960,
            "model-00004-of-00004.safetensors": 1073741952,
            "model.safetensors.index.json": 26922,
            "params.json": 296,
            "special_tokens_map.json": 414,
            "tekken.json": 14801223,
            "tokenizer.json": 17078136,
            "tokenizer_config.json": 181258,
        },
    },
    "w4ffl35/Ministral-8B-Instruct-2410-doublequant": {
        "path_settings": "llm_causallm_model_path",
        "context_length": 131072,
        "capabilities": {
            "function_calling": True,
            "thinking_capable": False,
            "rag_capable": True,
            "vision_capable": False,
            "code_capable": True,
            "is_embedding_model": False,
        },
        "files": {
            "config.json": 1223,
            "generation_config.json": 111,
            "model-00001-of-00002.safetensors": 4657954056,
            "model-00002-of-00002.safetensors": 1073741952,
            "model.safetensors.index.json": 148827,
            "params.json": 257,
            "special_tokens_map.json": 414,
            "tekken.json": 14801223,
            "tokenizer.json": 17078136,
            "tokenizer_config.json": 181258,
        },
    },
    "sentence-transformers/sentence-t5-large": {
        "path_settings": "sentence_transformers_path",
        "context_length": 512,
        "capabilities": {
            "function_calling": False,
            "thinking_capable": False,
            "rag_capable": False,
            "vision_capable": False,
            "code_capable": False,
            "is_embedding_model": True,
        },
        "files": {
            "1_Pooling/config.json": 190,
            "2_Dense/config.json": 116,
            "2_Dense/model.safetensors": 3145848,
            "config.json": 1388,
            "config_sentence_transformers.json": 122,
            "model.safetensors": 669902800,
            "modules.json": 461,
            "sentence_bert_config.json": 53,
            "special_tokens_map.json": 1786,
            "spiece.model": 791656,
            "tokenizer.json": 1387554,
            "tokenizer_config.json": 1924,
        },
    },
    "intfloat/e5-large": {
        "path_settings": "text_embedding",
        "context_length": 512,
        "capabilities": {
            "function_calling": False,
            "thinking_capable": False,
            "rag_capable": False,
            "vision_capable": False,
            "code_capable": False,
            "is_embedding_model": True,
        },
        "files": {
            "1_Pooling/config.json": 201,
            "config.json": 611,
            "model.safetensors": 1340616616,
            "modules.json": 387,
            "sentence_bert_config.json": 57,
            "special_tokens_map.json": 112,
            "tokenizer.json": 466081,
            "tokenizer_config.json": 385,
            "vocab.txt": 231508,
        },
    },
    "microsoft/Fara-7B": {
        "path_settings": "llm_fara_model_path",
        "context_length": 32768,
        "capabilities": {
            "function_calling": False,
            "thinking_capable": False,
            "rag_capable": True,
            "vision_capable": True,
            "code_capable": False,
            "is_embedding_model": False,
        },
        "files": {
            "added_tokens.json": 605,
            "chat_template.jinja": 1017,
            "config.json": 2490,
            "generation_config.json": 214,
            "merges.txt": 1671853,
            "model-00001-of-00004.safetensors": 4968243272,
            "model-00002-of-00004.safetensors": 4991495784,
            "model-00003-of-00004.safetensors": 4932751008,
            "model-00004-of-00004.safetensors": 1691924352,
            "model.safetensors.index.json": 57618,
            "preprocessor_config.json": 575,
            "special_tokens_map.json": 613,
            "tokenizer.json": 11421896,
            "tokenizer_config.json": 4730,
            "video_preprocessor_config.json": 1730,
            "vocab.json": 2776833,
        },
    },
}
