"""Worker for HuggingFace model downloads with parallel file downloading using Python threads."""

import os
import time
from pathlib import Path
from queue import Queue
from typing import Dict
import threading
import requests
import traceback

from airunner.components.application.workers.worker import Worker
from airunner.enums import SignalCode, QueueType
from airunner.components.llm.utils.model_downloader import (
    HuggingFaceDownloader,
)
from airunner.utils.settings.get_qsettings import get_qsettings


class SingleFileDownloadWorker(QObject):
    """Worker for downloading a single file in a separate thread."""

    progress = Signal(
        str, "qulonglong", "qulonglong"
    )  # (filename, downloaded, total)
    finished = Signal(str)  # filename
    failed = Signal(str, Exception)  # (filename, exception)

    def __init__(
        self,
        repo_id: str,
        filename: str,
        file_size: int,
        temp_path: Path,
        final_path: Path,
        api_key: str = "",
    ):
        super().__init__()
        self.repo_id = repo_id
        self.filename = filename
        self.file_size = file_size
        self.temp_path = temp_path
        self.final_path = final_path
        self.api_key = api_key
        self.is_cancelled = False
        self.downloaded = 0

    def cancel(self):
        """Cancel this download."""
        self.is_cancelled = True

    def run(self):
        """Download the file."""
        url = f"https://huggingface.co/{self.repo_id}/resolve/main/{self.filename}"

        # Ensure parent dirs exist
        self.temp_path.parent.mkdir(parents=True, exist_ok=True)

        headers = {}
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"

        try:
            # Debug: Log the start of download attempt

            with requests.get(
                url, headers=headers, stream=True, timeout=30
            ) as response:
                response.raise_for_status()

                # Debug: Log successful connection

                # Get actual size from headers if available
                content_length = response.headers.get("content-length")
                if content_length:
                    self.file_size = int(content_length)

                self.downloaded = 0
                with open(self.temp_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if self.is_cancelled:
                            f.close()
                            if os.path.exists(self.temp_path):
                                os.remove(self.temp_path)
                            return

                        if chunk:
                            f.write(chunk)
                            self.downloaded += len(chunk)

                            # Emit progress (throttle to every 100 chunks to avoid spam)
                            if (
                                self.file_size > 0
                                and (self.downloaded % (8192 * 100)) < 8192
                            ):
                                self.progress.emit(
                                    self.filename,
                                    self.downloaded,
                                    self.file_size,
                                )

                # Move to final location
                self.final_path.parent.mkdir(parents=True, exist_ok=True)
                os.replace(str(self.temp_path), str(self.final_path))

                self.finished.emit(self.filename)

        except Exception as e:
            # Debug: Log the error
            traceback.print_exc()

            # Clean up partial file
            if os.path.exists(self.temp_path):
                try:
                    os.remove(self.temp_path)
                except Exception:
                    pass
            self.failed.emit(self.filename, e)


class HuggingFaceDownloadWorker(MediatorMixin, QObject):
    """
    Worker class for downloading HuggingFace models with progress tracking and cancellation support.

    Similar to CivitAIDownloadWorker but handles:
    - Multiple files per model
    - Model type detection (mistral vs llm)
    - File pattern filtering
    - Tokenizer preservation
    """

    # Signals
    progress = Signal(
        "qulonglong", "qulonglong"
    )  # (downloaded_bytes, total_bytes)
    file_progress = Signal(
        str, "qulonglong", "qulonglong"
    )  # (filename, downloaded, total)
    finished = Signal(str)  # model_path
    failed = Signal(Exception)

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.queue = Queue()
        self.running = False
        self.is_cancelled = False
        self.downloader = HuggingFaceDownloader()
        self._model_path = None
        self._temp_dir = None
        self._total_downloaded = 0
        self._total_size = 0
        self._file_workers: Dict[str, SingleFileDownloadWorker] = {}
        self._file_threads: Dict[str, QThread] = {}
        self._file_progress: Dict[str, int] = (
            {}
        )  # Track downloaded bytes per file
        self._file_sizes: Dict[str, int] = {}  # Track total size per file
        self._completed_files = set()
        self._failed_files = set()
        self._progress_lock = Lock()  # Thread-safe progress tracking

    def add_to_queue(self, data: dict):
        """
        Add a download task to the queue.

        Args:
            data: Dict with keys:
                - repo_id: str (e.g., "mistralai/Ministral-8B-Instruct-2410")
                - model_type: str ("mistral" or "llm")
                - output_dir: Optional[str] (default: ~/.local/share/airunner/text/models/llm/causallm)
        """
        self.queue.put(data)

    def cancel(self):
        """Cancel the current download process and clean up partial files."""
        self.is_cancelled = True
        self.running = False

        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {"message": "Cancelling all downloads..."},
        )

        # Cancel all file workers
        for worker in self._file_workers.values():
            worker.cancel()

        # Wait for threads to finish
        for thread in self._file_threads.values():
            if thread.isRunning():
                thread.quit()
                thread.wait(1000)  # Wait up to 1 second

        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {"message": "Download cancelled by user"},
        )

        # Clean up temporary directory
        if self._temp_dir and os.path.exists(self._temp_dir):
            try:
                for entry in Path(self._temp_dir).rglob("*"):
                    try:
                        if entry.is_file():
                            entry.unlink()
                    except Exception:
                        pass
                Path(self._temp_dir).rmdir()
                self.emit_signal(
                    SignalCode.UPDATE_DOWNLOAD_LOG,
                    {"message": "Cleaned up temporary files"},
                )
            except Exception as e:
                self.emit_signal(
                    SignalCode.UPDATE_DOWNLOAD_LOG,
                    {"message": f"Failed to clean up temp dir: {e}"},
                )
                Path(self._temp_dir).rmdir()
                self.emit_signal(
                    SignalCode.UPDATE_DOWNLOAD_LOG,
                    {
                        "message": f"Removed temp download directory: {self._temp_dir}"
                    },
                )
            except Exception as e:
                self.emit_signal(
                    SignalCode.UPDATE_DOWNLOAD_LOG,
                    {"message": f"Failed to remove temp dir: {e}"},
                )

        # Clean up empty model directory
        if self._model_path and os.path.exists(self._model_path):
            try:
                # Only remove if directory is empty or only has partial downloads
                files = list(Path(self._model_path).glob("*"))
                if len(files) == 0:
                    os.rmdir(self._model_path)
                    self.emit_signal(
                        SignalCode.UPDATE_DOWNLOAD_LOG,
                        {
                            "message": f"Cleaned up empty directory: {os.path.basename(self._model_path)}"
                        },
                    )
                else:
                    self.emit_signal(
                        SignalCode.UPDATE_DOWNLOAD_LOG,
                        {
                            "message": f"Partial download remains in: {self._model_path}"
                        },
                    )
            except Exception as e:
                self.emit_signal(
                    SignalCode.UPDATE_DOWNLOAD_LOG,
                    {"message": f"Failed to clean up directory: {e}"},
                )

    def download(self):
        """Process the download queue."""
        self.running = True
        while self.running and not self.is_cancelled:
            if self.queue.empty():
                time.sleep(0.1)
                continue

            try:
                task_data = self.queue.get()
                self._download_model(task_data)
            except Exception as e:
                self.failed.emit(e)
                self.emit_signal(
                    SignalCode.UPDATE_DOWNLOAD_LOG,
                    {"message": f"Error: {str(e)}"},
                )
            finally:
                self.running = False

    def _download_model(self, task_data: dict):
        """Download a complete model with all files."""
        repo_id = task_data["repo_id"]
        model_type = task_data.get("model_type", "llm")
        output_dir = task_data.get("output_dir")

        # Setup UI
        self.emit_signal(SignalCode.CLEAR_DOWNLOAD_STATUS_BAR)
        self.emit_signal(
            SignalCode.SET_DOWNLOAD_STATUS_LABEL,
            {"message": f"Downloading {repo_id.split('/')[-1]}"},
        )
        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {"message": f"Starting download: {repo_id}"},
        )

        # Determine output directory
        if output_dir is None:
            output_dir = os.path.expanduser(
                "~/.local/share/airunner/text/models/llm/causallm"
            )

        # Construct model path
        model_name = repo_id.split("/")[-1]
        model_path = Path(output_dir) / model_name

        # Check if already downloaded (with all required files) BEFORE creating directories
        if self._check_existing(model_path, repo_id, model_type):
            return

        # Create output directory and temp directory for new download
        model_path.mkdir(parents=True, exist_ok=True)
        temp_dir = model_path / ".part_download"
        temp_dir.mkdir(parents=True, exist_ok=True)
        self._temp_dir = str(temp_dir)

        # Store model path for cleanup on cancel
        self._model_path = str(model_path)

        # Get file list
        try:
            files = self.downloader.get_model_files(repo_id)
        except Exception as e:
            raise RuntimeError(f"Failed to list files for {repo_id}: {e}")

        # Filter files (exclude consolidated, bin files)
        required_files = self.downloader.REQUIRED_FILES.get(
            model_type, self.downloader.REQUIRED_FILES["llm"]
        )

        files_to_download = []
        total_size = 0

        for file_info in files:
            filename = file_info.get("path", "")
            file_size = file_info.get("size", 0)

            # Skip directories
            if file_info.get("type") == "directory":
                continue

            # Skip consolidated files
            if "consolidated" in filename.lower():
                continue

            # Skip .bin files
            if filename.endswith(".bin") or filename.endswith(".msgpack"):
                continue

            # Always download required files
            if filename in required_files:
                files_to_download.append((filename, file_size))
                total_size += file_size
                continue

            # Download safetensors and json files
            if filename.endswith(".safetensors") or filename.endswith(".json"):
                files_to_download.append((filename, file_size))
                total_size += file_size

        self._total_size = total_size
        self._total_downloaded = 0

        # Diagnostic: if no files were selected for download, show what was listed
        if len(files_to_download) == 0:
            listed = [f.get("path") for f in files]
            self.emit_signal(
                SignalCode.UPDATE_DOWNLOAD_LOG,
                {
                    "message": (
                        f"No files selected for download from {repo_id}. Listed files: {listed}"
                    )
                },
            )
            # If required files weren't in the listing, raise a clear error
            listed_basenames = {f.get("path") for f in files}
            missing_required = [
                r for r in required_files if r not in listed_basenames
            ]
            if missing_required:
                raise RuntimeError(
                    f"Required files not listed for {repo_id}: {missing_required}"
                )
            else:
                raise RuntimeError(
                    f"No downloadable files found for {repo_id}"
                )

        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {
                "message": f"Downloading {len(files_to_download)} files ({total_size / 1024**3:.2f} GB) in parallel"
            },
        )

        # Get API key for authentication
        settings = get_qsettings()
        api_key = settings.value("huggingface/api_key", "")

        # Start parallel downloads for each file
        for filename, file_size in files_to_download:
            if self.is_cancelled:
                return

            self._file_sizes[filename] = file_size
            self._file_progress[filename] = 0

            # Create worker and thread for this file
            temp_path = temp_dir / filename
            final_path = model_path / filename

            self.emit_signal(
                SignalCode.UPDATE_DOWNLOAD_LOG,
                {"message": f"Starting download thread for {filename}..."},
            )

            worker = SingleFileDownloadWorker(
                repo_id, filename, file_size, temp_path, final_path, api_key
            )
            thread = QThread()

            # Move worker to thread
            worker.moveToThread(thread)

            # Connect signals
            worker.progress.connect(self._on_file_progress)
            worker.finished.connect(self._on_file_finished)
            worker.failed.connect(self._on_file_failed)

            # Connect thread lifecycle
            thread.started.connect(worker.run)
            thread.finished.connect(thread.deleteLater)

            # Store references
            self._file_workers[filename] = worker
            self._file_threads[filename] = thread

            # Start the download
            thread.start()

        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {
                "message": f"Started {len(files_to_download)} download threads, waiting for completion..."
            },
        )

        # Wait for all downloads to complete
        while not self.is_cancelled:
            all_done = len(self._completed_files) + len(
                self._failed_files
            ) == len(files_to_download)
            if all_done:
                break
            time.sleep(0.1)

        # Check results
        if self.is_cancelled:
            return

        if self._failed_files:
            # Some files failed
            failed_list = ", ".join(self._failed_files)
            raise RuntimeError(f"Failed to download files: {failed_list}")

        # Complete - cleanup temp dir
        try:
            if self._temp_dir and os.path.exists(self._temp_dir):
                if not any(Path(self._temp_dir).iterdir()):
                    Path(self._temp_dir).rmdir()
                    self.emit_signal(
                        SignalCode.UPDATE_DOWNLOAD_LOG,
                        {"message": "Cleaned up temporary directory"},
                    )
        except Exception:
            pass

        # Verify required files are present in final model path
        required_files = self.downloader.REQUIRED_FILES.get(
            model_type, self.downloader.REQUIRED_FILES["llm"]
        )
        missing = []
        for req in required_files:
            found = False
            for p in model_path.rglob(req):
                if p.is_file():
                    found = True
                    break
                if not found:
                    missing.append(req)

            if missing:
                # Gather diagnostics: files that exist in final path and temp dir
                found_files = []
                try:
                    for p in model_path.rglob("*"):
                        try:
                            if p.is_file():
                                found_files.append(
                                    str(p.relative_to(model_path))
                                )
                        except Exception:
                            pass
                except Exception:
                    pass

                temp_files = []
                try:
                    if self._temp_dir and os.path.exists(self._temp_dir):
                        for p in Path(self._temp_dir).rglob("*"):
                            try:
                                if p.is_file():
                                    temp_files.append(
                                        str(p.relative_to(self._temp_dir))
                                    )
                            except Exception:
                                pass
                except Exception:
                    pass

                # Clean up incomplete model folder
                try:
                    for entry in model_path.rglob("*"):
                        try:
                            if entry.is_file():
                                entry.unlink()
                        except Exception:
                            pass
                    try:
                        Path(model_path).rmdir()
                    except Exception:
                        pass
                except Exception:
                    pass

                diag_msg = f"Missing: {', '.join(missing)}; found_files: {found_files}; temp_files: {temp_files}"
                raise RuntimeError(
                    f"{', '.join(missing)} not found in {model_path} - {diag_msg}"
                )

            self.emit_signal(
                SignalCode.UPDATE_DOWNLOAD_LOG,
                {"message": f"Download complete: {model_path}"},
            )
            self.finished.emit(str(model_path))

    def _check_existing(
        self, model_path: Path, repo_id: str, model_type: str = "llm"
    ) -> bool:
        """Check if model already exists with required files."""
        if not model_path.exists():
            return False

        # Check for required files, not just any files
        required_files = self.downloader.REQUIRED_FILES.get(
            model_type, self.downloader.REQUIRED_FILES["llm"]
        )

        # Verify all required files exist
        missing = []
        for req_file in required_files:
            if not (model_path / req_file).exists():
                missing.append(req_file)

        if missing:
            # Model directory exists but is incomplete
            self.emit_signal(
                SignalCode.UPDATE_DOWNLOAD_LOG,
                {
                    "message": f"Model directory exists but is incomplete (missing: {', '.join(missing)}), will download..."
                },
            )
            return False

        # All required files present - model is complete
        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {"message": f"Model already exists: {model_path}"},
        )
        self.finished.emit(str(model_path))
        return True

    def _on_file_progress(self, filename: str, downloaded: int, total: int):
        """Handle progress update from a file download worker."""
        with self._progress_lock:
            # Update this file's progress
            self._file_progress[filename] = downloaded
            self._file_sizes[filename] = total

            # Calculate overall progress
            total_downloaded = sum(self._file_progress.values())
            total_size = sum(self._file_sizes.values())

            # Emit per-file progress
            self.file_progress.emit(filename, downloaded, total)

            # Emit overall progress
            if total_size > 0:
                self.progress.emit(total_downloaded, total_size)

    def _on_file_finished(self, filename: str):
        """Handle completion of a file download."""
        with self._progress_lock:
            self._completed_files.add(filename)

        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {"message": f"✓ Completed {filename}"},
        )

    def _on_file_failed(self, filename: str, error: Exception):
        """Handle failure of a file download."""
        with self._progress_lock:
            self._failed_files.add(filename)

        self.emit_signal(
            SignalCode.UPDATE_DOWNLOAD_LOG,
            {"message": f"✗ Failed {filename}: {error}"},
        )
